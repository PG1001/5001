{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data & remove null value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>MO HLADR+ MFI (cells/ul)</th>\n",
       "      <th>Neu CD64+MFI (cells/ul)</th>\n",
       "      <th>CD3+T (cells/ul)</th>\n",
       "      <th>CD8+T (cells/ul)</th>\n",
       "      <th>CD4+T (cells/ul)</th>\n",
       "      <th>NK (cells/ul)</th>\n",
       "      <th>CD19+ (cells/ul)</th>\n",
       "      <th>CD45+ (cells/ul)</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex 0M1F</th>\n",
       "      <th>Mono CD64+MFI (cells/ul)</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3556.0</td>\n",
       "      <td>2489.0</td>\n",
       "      <td>265.19</td>\n",
       "      <td>77.53</td>\n",
       "      <td>176.55</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.20</td>\n",
       "      <td>307.91</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>7515.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1906.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>1442.61</td>\n",
       "      <td>551.90</td>\n",
       "      <td>876.07</td>\n",
       "      <td>112.10</td>\n",
       "      <td>168.15</td>\n",
       "      <td>1735.48</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1756.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1586.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1332.74</td>\n",
       "      <td>684.20</td>\n",
       "      <td>655.26</td>\n",
       "      <td>244.95</td>\n",
       "      <td>216.52</td>\n",
       "      <td>1820.04</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1311.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>683.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>419.23</td>\n",
       "      <td>255.80</td>\n",
       "      <td>162.17</td>\n",
       "      <td>72.05</td>\n",
       "      <td>44.68</td>\n",
       "      <td>538.22</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>1443.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1032.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1102.72</td>\n",
       "      <td>480.27</td>\n",
       "      <td>625.30</td>\n",
       "      <td>188.78</td>\n",
       "      <td>130.77</td>\n",
       "      <td>1427.97</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1542.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>82</td>\n",
       "      <td>626.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1771.57</td>\n",
       "      <td>666.99</td>\n",
       "      <td>1117.48</td>\n",
       "      <td>360.21</td>\n",
       "      <td>118.84</td>\n",
       "      <td>2306.82</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>1521.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>83</td>\n",
       "      <td>1237.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1348.53</td>\n",
       "      <td>428.09</td>\n",
       "      <td>924.69</td>\n",
       "      <td>120.02</td>\n",
       "      <td>48.67</td>\n",
       "      <td>1524.78</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>1345.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>84</td>\n",
       "      <td>634.0</td>\n",
       "      <td>1002.0</td>\n",
       "      <td>1300.00</td>\n",
       "      <td>558.00</td>\n",
       "      <td>724.00</td>\n",
       "      <td>67.00</td>\n",
       "      <td>105.00</td>\n",
       "      <td>1484.26</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>2926.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>85</td>\n",
       "      <td>112.0</td>\n",
       "      <td>884.0</td>\n",
       "      <td>942.83</td>\n",
       "      <td>378.49</td>\n",
       "      <td>567.06</td>\n",
       "      <td>116.77</td>\n",
       "      <td>31.81</td>\n",
       "      <td>1104.59</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>2352.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>86</td>\n",
       "      <td>195.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>724.00</td>\n",
       "      <td>364.00</td>\n",
       "      <td>361.00</td>\n",
       "      <td>18.00</td>\n",
       "      <td>155.00</td>\n",
       "      <td>897.00</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>2445.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  MO HLADR+ MFI (cells/ul)  Neu CD64+MFI (cells/ul)  CD3+T (cells/ul)  \\\n",
       "0    0                    3556.0                   2489.0            265.19   \n",
       "1    1                    1906.0                    134.0           1442.61   \n",
       "2    2                    1586.0                     71.0           1332.74   \n",
       "3    3                     683.0                     94.0            419.23   \n",
       "4    4                    1032.0                     71.0           1102.72   \n",
       "..  ..                       ...                      ...               ...   \n",
       "82  82                     626.0                     68.0           1771.57   \n",
       "83  83                    1237.0                     71.0           1348.53   \n",
       "84  84                     634.0                   1002.0           1300.00   \n",
       "85  85                     112.0                    884.0            942.83   \n",
       "86  86                     195.0                    213.0            724.00   \n",
       "\n",
       "    CD8+T (cells/ul)  CD4+T (cells/ul)  NK (cells/ul)  CD19+ (cells/ul)  \\\n",
       "0              77.53            176.55           0.00              4.20   \n",
       "1             551.90            876.07         112.10            168.15   \n",
       "2             684.20            655.26         244.95            216.52   \n",
       "3             255.80            162.17          72.05             44.68   \n",
       "4             480.27            625.30         188.78            130.77   \n",
       "..               ...               ...            ...               ...   \n",
       "82            666.99           1117.48         360.21            118.84   \n",
       "83            428.09            924.69         120.02             48.67   \n",
       "84            558.00            724.00          67.00            105.00   \n",
       "85            378.49            567.06         116.77             31.81   \n",
       "86            364.00            361.00          18.00            155.00   \n",
       "\n",
       "    CD45+ (cells/ul)  Age  Sex 0M1F  Mono CD64+MFI (cells/ul)  label  \n",
       "0             307.91   52         0                    7515.0      1  \n",
       "1            1735.48   20         1                    1756.0      0  \n",
       "2            1820.04   28         1                    1311.0      0  \n",
       "3             538.22   55         1                    1443.0      0  \n",
       "4            1427.97   28         1                    1542.0      0  \n",
       "..               ...  ...       ...                       ...    ...  \n",
       "82           2306.82   42         1                    1521.0      0  \n",
       "83           1524.78   56         0                    1345.0      0  \n",
       "84           1484.26   34         0                    2926.0      1  \n",
       "85           1104.59   33         1                    2352.0      1  \n",
       "86            897.00   19         1                    2445.0      1  \n",
       "\n",
       "[87 rows x 13 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv') \n",
    "sub = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MO HLADR+ MFI (cells/ul)',\n",
       " 'Neu CD64+MFI (cells/ul)',\n",
       " 'CD3+T (cells/ul)',\n",
       " 'CD8+T (cells/ul)',\n",
       " 'CD4+T (cells/ul)',\n",
       " 'NK (cells/ul)',\n",
       " 'CD19+ (cells/ul)',\n",
       " 'CD45+ (cells/ul)',\n",
       " 'Age',\n",
       " 'Sex 0M1F',\n",
       " 'Mono CD64+MFI (cells/ul)']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the features of the dataset\n",
    "features = train.columns.values.tolist()[1:-1]\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                          False\n",
      "MO HLADR+ MFI (cells/ul)     True\n",
      "Neu CD64+MFI (cells/ul)      True\n",
      "CD3+T (cells/ul)            False\n",
      "CD8+T (cells/ul)            False\n",
      "CD4+T (cells/ul)            False\n",
      "NK (cells/ul)               False\n",
      "CD19+ (cells/ul)            False\n",
      "CD45+ (cells/ul)            False\n",
      "Age                         False\n",
      "Sex 0M1F                    False\n",
      "Mono CD64+MFI (cells/ul)     True\n",
      "label                       False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# Check if there are NaN value \n",
    "print(np.isnan(train).any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>MO HLADR+ MFI (cells/ul)</th>\n",
       "      <th>Neu CD64+MFI (cells/ul)</th>\n",
       "      <th>CD3+T (cells/ul)</th>\n",
       "      <th>CD8+T (cells/ul)</th>\n",
       "      <th>CD4+T (cells/ul)</th>\n",
       "      <th>NK (cells/ul)</th>\n",
       "      <th>CD19+ (cells/ul)</th>\n",
       "      <th>CD45+ (cells/ul)</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex 0M1F</th>\n",
       "      <th>Mono CD64+MFI (cells/ul)</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3556.0</td>\n",
       "      <td>2489.0</td>\n",
       "      <td>265.19</td>\n",
       "      <td>77.53</td>\n",
       "      <td>176.55</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.20</td>\n",
       "      <td>307.91</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>7515.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1906.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>1442.61</td>\n",
       "      <td>551.90</td>\n",
       "      <td>876.07</td>\n",
       "      <td>112.10</td>\n",
       "      <td>168.15</td>\n",
       "      <td>1735.48</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1756.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1586.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1332.74</td>\n",
       "      <td>684.20</td>\n",
       "      <td>655.26</td>\n",
       "      <td>244.95</td>\n",
       "      <td>216.52</td>\n",
       "      <td>1820.04</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1311.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>683.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>419.23</td>\n",
       "      <td>255.80</td>\n",
       "      <td>162.17</td>\n",
       "      <td>72.05</td>\n",
       "      <td>44.68</td>\n",
       "      <td>538.22</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>1443.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1032.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1102.72</td>\n",
       "      <td>480.27</td>\n",
       "      <td>625.30</td>\n",
       "      <td>188.78</td>\n",
       "      <td>130.77</td>\n",
       "      <td>1427.97</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1542.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>82</td>\n",
       "      <td>626.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1771.57</td>\n",
       "      <td>666.99</td>\n",
       "      <td>1117.48</td>\n",
       "      <td>360.21</td>\n",
       "      <td>118.84</td>\n",
       "      <td>2306.82</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>1521.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>83</td>\n",
       "      <td>1237.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1348.53</td>\n",
       "      <td>428.09</td>\n",
       "      <td>924.69</td>\n",
       "      <td>120.02</td>\n",
       "      <td>48.67</td>\n",
       "      <td>1524.78</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>1345.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>84</td>\n",
       "      <td>634.0</td>\n",
       "      <td>1002.0</td>\n",
       "      <td>1300.00</td>\n",
       "      <td>558.00</td>\n",
       "      <td>724.00</td>\n",
       "      <td>67.00</td>\n",
       "      <td>105.00</td>\n",
       "      <td>1484.26</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>2926.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>85</td>\n",
       "      <td>112.0</td>\n",
       "      <td>884.0</td>\n",
       "      <td>942.83</td>\n",
       "      <td>378.49</td>\n",
       "      <td>567.06</td>\n",
       "      <td>116.77</td>\n",
       "      <td>31.81</td>\n",
       "      <td>1104.59</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>2352.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>86</td>\n",
       "      <td>195.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>724.00</td>\n",
       "      <td>364.00</td>\n",
       "      <td>361.00</td>\n",
       "      <td>18.00</td>\n",
       "      <td>155.00</td>\n",
       "      <td>897.00</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>2445.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  MO HLADR+ MFI (cells/ul)  Neu CD64+MFI (cells/ul)  CD3+T (cells/ul)  \\\n",
       "0    0                    3556.0                   2489.0            265.19   \n",
       "1    1                    1906.0                    134.0           1442.61   \n",
       "2    2                    1586.0                     71.0           1332.74   \n",
       "3    3                     683.0                     94.0            419.23   \n",
       "4    4                    1032.0                     71.0           1102.72   \n",
       "..  ..                       ...                      ...               ...   \n",
       "82  82                     626.0                     68.0           1771.57   \n",
       "83  83                    1237.0                     71.0           1348.53   \n",
       "84  84                     634.0                   1002.0           1300.00   \n",
       "85  85                     112.0                    884.0            942.83   \n",
       "86  86                     195.0                    213.0            724.00   \n",
       "\n",
       "    CD8+T (cells/ul)  CD4+T (cells/ul)  NK (cells/ul)  CD19+ (cells/ul)  \\\n",
       "0              77.53            176.55           0.00              4.20   \n",
       "1             551.90            876.07         112.10            168.15   \n",
       "2             684.20            655.26         244.95            216.52   \n",
       "3             255.80            162.17          72.05             44.68   \n",
       "4             480.27            625.30         188.78            130.77   \n",
       "..               ...               ...            ...               ...   \n",
       "82            666.99           1117.48         360.21            118.84   \n",
       "83            428.09            924.69         120.02             48.67   \n",
       "84            558.00            724.00          67.00            105.00   \n",
       "85            378.49            567.06         116.77             31.81   \n",
       "86            364.00            361.00          18.00            155.00   \n",
       "\n",
       "    CD45+ (cells/ul)  Age  Sex 0M1F  Mono CD64+MFI (cells/ul)  label  \n",
       "0             307.91   52         0                    7515.0      1  \n",
       "1            1735.48   20         1                    1756.0      0  \n",
       "2            1820.04   28         1                    1311.0      0  \n",
       "3             538.22   55         1                    1443.0      0  \n",
       "4            1427.97   28         1                    1542.0      0  \n",
       "..               ...  ...       ...                       ...    ...  \n",
       "82           2306.82   42         1                    1521.0      0  \n",
       "83           1524.78   56         0                    1345.0      0  \n",
       "84           1484.26   34         0                    2926.0      1  \n",
       "85           1104.59   33         1                    2352.0      1  \n",
       "86            897.00   19         1                    2445.0      1  \n",
       "\n",
       "[86 rows x 13 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop rows with NaN value \n",
    "train.dropna(inplace=True)\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the dataset for cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of training dataï¼š68ï¼Œthe number of testing dataï¼š18\n"
     ]
    }
   ],
   "source": [
    "train_X = train[features]\n",
    "train_Y = train['label']\n",
    "test_X = test[features]\n",
    "\n",
    "# cross validation split\n",
    "sub_train_X, sub_test_X, sub_train_Y, sub_test_Y = train_test_split(train_X, train_Y, test_size=0.2, random_state=42)\n",
    "\n",
    "print('The number of training dataï¼š{}ï¼Œthe number of testing dataï¼š{}'.format(len(sub_train_X), len(sub_test_X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95         9\n",
      "           1       1.00      0.89      0.94         9\n",
      "\n",
      "    accuracy                           0.94        18\n",
      "   macro avg       0.95      0.94      0.94        18\n",
      "weighted avg       0.95      0.94      0.94        18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "rfc = RandomForestClassifier(max_depth = 4, random_state = 0) # Build model\n",
    "\n",
    "rfc.fit(sub_train_X, sub_train_Y) # Train model\n",
    "y_pred = rfc.predict(sub_test_X) # Test model\n",
    "\n",
    "print(classification_report(sub_test_Y, y_pred, target_names=None))\n",
    "\n",
    "test_pred_rfc = rfc.predict(test_X)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['label'] = test_pred_rfc\n",
    "\n",
    "df.to_csv('submission_RF.csv', index=True, index_label='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.999999999999996"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# absolute score on the private leaderboard\n",
    "15 + (0.94 - 0.9) * 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95         9\n",
      "           1       1.00      0.89      0.94         9\n",
      "\n",
      "    accuracy                           0.94        18\n",
      "   macro avg       0.95      0.94      0.94        18\n",
      "weighted avg       0.95      0.94      0.94        18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree - Gini\n",
    "dt_model_gini = DecisionTreeClassifier(max_depth = 3) # Build model\n",
    "dt_model_gini.fit(sub_train_X, sub_train_Y) # Train model\n",
    "y_pred_gini = dt_model_gini.predict(sub_test_X) # Test model\n",
    "\n",
    "print(classification_report(sub_test_Y, y_pred_gini, target_names=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_gini = dt_model_gini.predict(test_X)\n",
    "test_pred_gini\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['label'] = test_pred_gini\n",
    "\n",
    "df.to_csv('submission_gini.csv', index=True, index_label='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95         9\n",
      "           1       1.00      0.89      0.94         9\n",
      "\n",
      "    accuracy                           0.94        18\n",
      "   macro avg       0.95      0.94      0.94        18\n",
      "weighted avg       0.95      0.94      0.94        18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 3) # Build model\n",
    "knn.fit(sub_train_X, sub_train_Y) # Train model\n",
    "y_pred = knn.predict(sub_test_X) # Test model\n",
    "\n",
    "print(classification_report(sub_test_Y, y_pred, target_names=None))\n",
    "\n",
    "test_pred_knn = knn.predict(test_X)\n",
    "test_pred_knn\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['label'] = test_pred_knn\n",
    "\n",
    "df.to_csv('submission_KNN.csv', index=True, index_label='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:27:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89         9\n",
      "           1       0.89      0.89      0.89         9\n",
      "\n",
      "    accuracy                           0.89        18\n",
      "   macro avg       0.89      0.89      0.89        18\n",
      "weighted avg       0.89      0.89      0.89        18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier()  # Build model\n",
    "xgb.fit(sub_train_X, sub_train_Y) # Train model\n",
    "y_pred = xgb.predict(sub_test_X) # Test model\n",
    "\n",
    "\n",
    "# predictions = [round(value) for value in y_pred]\n",
    "\n",
    "\n",
    "print(classification_report(sub_test_Y, y_pred, target_names=None))\n",
    "\n",
    "test_pred_xgb = xgb.predict(test_X)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['label'] = test_pred_xgb\n",
    "\n",
    "df.to_csv('submission_XGB.csv', index=True, index_label='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on H=1 Epoch [400/400] Loss: 0.6134   Accuracy: 70.5882%\n",
      "Subset testing on H=1, Loss of testing 0.7389\n",
      "Subset testing on H=1, Accuracy of testing 50.0000 %\n",
      "Train on H=2 Epoch [400/400] Loss: 0.5942   Accuracy: 72.0588%\n",
      "Subset testing on H=2, Loss of testing 0.6886\n",
      "Subset testing on H=2, Accuracy of testing 55.5556 %\n",
      "Train on H=3 Epoch [400/400] Loss: 0.6112   Accuracy: 70.5882%\n",
      "Subset testing on H=3, Loss of testing 0.7452\n",
      "Subset testing on H=3, Accuracy of testing 50.0000 %\n",
      "Train on H=4 Epoch [400/400] Loss: 0.6115   Accuracy: 70.5882%\n",
      "Subset testing on H=4, Loss of testing 0.7444\n",
      "Subset testing on H=4, Accuracy of testing 50.0000 %\n",
      "Train on H=5 Epoch [400/400] Loss: 0.6091   Accuracy: 70.5882%\n",
      "Subset testing on H=5, Loss of testing 0.7534\n",
      "Subset testing on H=5, Accuracy of testing 50.0000 %\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\n",
      "H_best= 2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn import metrics\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Parameters\n",
    "D_in, D_out = len(features), 2     # D_in is feature number\n",
    "lr = 0.01\n",
    "num_epoch = 400\n",
    "hidden_unit = [1, 2, 3, 4, 5]\n",
    "\n",
    "loss_H = {} # store the loss for cross validation of H, get the best hidden unit\n",
    "train_loss, Subset_test_loss = [],[] # used for storing the result and show the graph \n",
    "train_accu, Subset_test_accu = [],[] # used for storing the result and show the graph\n",
    "\n",
    "for H in hidden_unit:\n",
    "    #-----Configurable neural network (H)-----\n",
    "    # build model\n",
    "    class Net(nn.Module):\n",
    "        def __init__(self, H): # H is variable\n",
    "            super(Net, self).__init__()\n",
    "            self.fc1 = nn.Linear(D_in, H)  # Single layer\n",
    "            self.fc2 = nn.Linear(H, D_out)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = self.fc2(x)\n",
    "            return x\n",
    "\n",
    "    net = Net(H)\n",
    "    #-------------------------------------------\n",
    "\n",
    "    # set optimizer and loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr = lr) # stochastic gradient descent\n",
    "\n",
    "    # train\n",
    "    for epoch in range(num_epoch):\n",
    "\n",
    "        X = torch.Tensor(sub_train_X.values)\n",
    "        Y = torch.LongTensor(sub_train_Y.values)\n",
    "        \n",
    "        # feedforward - backprop\n",
    "        optimizer.zero_grad() # Zero the gradients before running the backward pass.\n",
    "        output = net(X)\n",
    "        loss = criterion(output, Y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        accu = 100 * torch.sum(Y==torch.max(output.data, 1)[1]).double() / len(Y)\n",
    "        if (epoch == num_epoch-1): # Only print the final result\n",
    "            print ('Train on H=%.f Epoch [%d/%d] Loss: %.4f   Accuracy: %.4f%%' \n",
    "                   %(H, epoch+1, num_epoch, loss.item(), accu.item()))\n",
    "            train_loss.append(loss.item())\n",
    "            train_accu.append(accu.item())\n",
    "\n",
    "    # Test on sub_test_X, sub_test_Y, get prediction\n",
    "    X = torch.Tensor(sub_test_X.values)\n",
    "    Y = torch.LongTensor(sub_test_Y)\n",
    "    output = net(X)\n",
    "    _, predicted = torch.max(output.data, 1)\n",
    "    loss = criterion(output, Y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # print accuracy and loss\n",
    "    print('Subset testing on H=%.f, Loss of testing %.4f' % (H, loss.item()))\n",
    "    print('Subset testing on H=%.f, Accuracy of testing %.4f %%' % (H, 100 * torch.sum(Y==predicted).double() / len(Y)))\n",
    "    loss_H[H] = (loss.item())\n",
    "    Subset_test_loss.append(loss.item())\n",
    "    Subset_test_accu.append(100 * torch.sum(Y==predicted).double() / len(Y))\n",
    "    #----------------------------------------------------------------------\n",
    "\n",
    "# After iteration, show the Training graph comparing the loss and accuracy with different H\n",
    "h = pd.DataFrame({\n",
    "    'Train loss': train_loss,\n",
    "    'Train accuracy': train_accu,\n",
    "    'Subset test loss': Subset_test_loss,\n",
    "    'Subset test accuracy': Subset_test_accu,})\n",
    "\n",
    "ax1 = h[['Train loss','Subset test loss']].plot(kind='bar')\n",
    "ax1.get_legend().remove()\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(ax1.get_xticks(),\n",
    "         h[['Train accuracy','Subset test accuracy']].values,\n",
    "         linestyle='-', marker='o', linewidth=2.0)\n",
    "\n",
    "\n",
    "ax1.set_ylabel(\"Loss\")\n",
    "ax2.set_ylabel(\"Accuracy\")\n",
    "\n",
    "ax1.set_xticklabels(hidden_unit, rotation = 0)\n",
    "\n",
    "plt.legend(['Cross validation train','Cross validation test'],\n",
    "           bbox_to_anchor = (1.6, 0.3))\n",
    "\n",
    "plt.title(\"Cross validation: loss and accuracy for different H\")\n",
    "plt.show()\n",
    "\n",
    "#--------------------------------------------------------------\n",
    "\n",
    "loss_H_order=sorted(loss_H.items(), key=lambda x:x[1]) # ascending order, the first one has the smallest loss\n",
    "H_best = loss_H_order[0][0] # get the best H(hidden layer units)\n",
    "\n",
    "print('\\t')\n",
    "print('H_best=', H_best)\n",
    "\n",
    "#===========Build a new model with the best H for each dataset============\n",
    "net = Net(H_best)\n",
    "\n",
    "# choose optimizer and loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr = lr)\n",
    "\n",
    "# train the train_X and train_Y with the the best parameter H_best\n",
    "for epoch in range(num_epoch):\n",
    "    X = torch.Tensor(train_X.values)\n",
    "    Y = torch.LongTensor(train_Y).long()\n",
    "\n",
    "    # feedforward - backprop\n",
    "    optimizer.zero_grad() # Zero the gradients before running the backward pass.\n",
    "    output = net(X)\n",
    "    loss = criterion(output, Y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    accu = 100 * torch.sum(Y==torch.max(output.data, 1)[1]).double() / len(Y)\n",
    "\n",
    "\n",
    "#===============Testing model=============================\n",
    "# get the prediction\n",
    "X = torch.Tensor(test_X.values)\n",
    "output = net(X)\n",
    "_, predicted = torch.max(output.data, 1)\n",
    "\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['label'] = predicted\n",
    "\n",
    "df.to_csv('submission_NN.csv', index=True, index_label='id')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
